---
title: "Final Project Report"
author: "Group E8"
date: "05/04/2022"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Public food safety is of concern to the general population. The Food Hygiene Agency in the United Kingdom puts out a report on the food hygiene rating in the boroughs of London from 2002 to 2022. The data is collected by multiple participating local authorities in the London area and was aggregated by the Food Hygiene Agency for honest communication between the government and citizens with topic of Health in mind. Based on both governmental and our concern, we will investigate the relationship between the food hygiene evaluation and the date of inspection, area (health authority), and business type of the food service provider. In this study, we want to generate a model that causally explains what determines good or bad in the hygiene evaluation of restaurants across London and, possibly, make predictive assessments such that it can help the public have more tooling and information for assessing the outcome of future restaurants hygiene inspections to help empower consumer consciousness. In the dataset, we will define a new variable food hygiene rating with a rating of 3 to 5 as ’good‘ hygiene condition and 0 to 2 as ‘not good’ hygiene condition in order to make our food hygiene evaluation a binary response variable. Furthermore, we will exclude all the businesses that have not gotten reviewed or have not been reviewed yet. For our model, there are 3 explanatory variables in our study. The food business type is a categorical variable with 5 levels: Restaurant/Cafe/Canteen, Retailers-other, Takeaway/sandwich shop, Other catering premises, and Hospitals/Childcare/Caring Premises. The date of inspection is the date at which the hygiene review took place, from 2002 to 2022, and we will exclude the data that does not have a date.


## Analysis

In order to study the proposed relationship (the casual analysis), the first steps are tidying and wrangling the data, and then performing descriptive data analysis. For tidying, the missing values were checked for and removed, the `RatingValue` has two factors, businesses that did not get reviewed and businesses that have yet to be reviewed, which will be removed, and extraneous variables were dropped such that the data set was well-structured and relevant to the proposed relationship. For wrangling, the `RatingDate` variable was split into three separate variables (`Year`, `Month`, and `Day`), the variable `RatingValue` was transformed into the new response variable `Pass` which is a factor of levels 0 and 1 where 0 represents the rating below 3 and 1 represents the rating value equal to or larger than 3 (i.e. converting ordinal factors into nominal bins).

For the descriptive analysis, several plots of the exploratory variables and the response variable were created. Since the response variable `Pass` is categorical, we agreed that bar plots and histograms are most suited to explore the data. The plots below include one histogram of `LocalAuthorityCode`, and two bar plots of `BusinessType` and `Pass`:

```{r f1, echo=FALSE, fig.cap="Histogram of Local Authority Code", out.width = '75%', out.height="75%", fig.align="center"}
knitr::include_graphics("./results/LAC_hist.png")
```

```{r f2, echo=FALSE, fig.cap="Bar Plot of Business Type", out.height="50%", out.width='100%', fig.align="center"}
knitr::include_graphics("./results/BT_bar.png")
```


```{r f3, echo=FALSE, fig.cap="Bar Plot of Rating Value", out.width = '50%', out.height="50%", fig.align="center"}
knitr::include_graphics("./results/RV_bar.png")
```


\newpage
We used the train-test methodology to evaluate the final model in this project. As such, it is essential to split the data into two data-sets: training and testing. We used 75% of the data to fit the model, and 25% of the data to test the prediction accuracy.

Since there are not that many variables, we decided to train a full logistic regression model containing all of the variables. Among the propose explanatory variables, there is one variable that is treated as a factor, `BusinessType`. Furthermore, the `LocalAuthorityCode` variable is comprised of discrete numbers which allows it to be treated as a factor as well; however, the values variate and it was deemed to overly increase the complexity of the model with marginal gain and, thus, was kept as a numeric variable. Moreover, there are no interaction terms in the model as it is not intuitive to explore any pairs of interactions among these variables. After fitting the model, a summary of the coefficients, test statistics, and Akaike Information Criterion (AIC) values are obtained in the summary of the fitted model. The model summary is attached in the Appendix.

The prediction results of the testing set are generated using the fitted model to evaluate the accuracy. A confusion matrix is also generated to show the number of true predicted and false predicted values. The matrix and the table of accuracy, as well as its interval, are shown below:

```{r echo=FALSE}
acc_df <- read.csv("./results/accuracy.csv")
colnames(acc_df) <- c("Criteria", "Value")
final_acc <- acc_df[1,2]
acc_df
```

```{r echo=FALSE}
cm_df <- read.csv("./results/conf_mat.csv")
colnames(cm_df) <- c("Prediction", "True_Value_0", "True_Value_1")
cm_df
```

The final accuracy of the model is `r final_acc`, and the AIC is almost 7000.

## Conclusion

## Reference

## Appendix - R Script

```{r results='hide',message=FALSE}
# R code for the final project report
library(tidyverse)
library(ggplot2)
library(GGally)
library(rsample)
library(InformationValue)
library(caret)
# Read the dataset
data <- read_csv("./data/food_hygiene_rating_data.csv", col_names=TRUE)

# Clean the dataset
data_eda <- data %>% 
  select(LocalAuthorityCode, RatingDate, BusinessType, RatingValue) %>%
  filter(RatingValue==0 | RatingValue==1 | RatingValue==2 | 
           RatingValue==3 | RatingValue==4 | RatingValue==5) %>%
  mutate(Pass = ifelse((RatingValue >= 3), 1, 0)) %>%
  mutate(Year = format(RatingDate, "%Y") %>% as.numeric(),
         Month = format(RatingDate, "%m") %>% as.numeric(),
         Day = format(RatingDate, "%d") %>% as.numeric(),
         BusinessType = BusinessType <- as.factor(BusinessType)) %>%
  select(-RatingDate) %>%
  drop_na()

```

```{r eval = FALSE}
# Visualization of the dataset
png("results/LAC_hist.png",width=800, height=600)
LAC_hist <- hist(data_eda$LocalAuthorityCode, 
                 xlab="Local Authority Code",
                 main="Histogram of Local Authority Code")
dev.off()

options(repr.plot.width = 15, repr.plot.height = 8)
ggplot(data=data_eda, aes(x=factor(BusinessType))) +
  geom_bar(stat="count") +
  xlab("Count") +
  ylab("Business Type")+
  ggtitle("Bar Plot of Business Type")+
  theme(plot.title = element_text(hjust = 0.5))+
  coord_flip()
ggsave("./results/BT_bar.png")

ggplot(data=data_eda, aes(x=factor(Pass)), height=3) +
  geom_bar(stat="count") +
  xlab("Count") +
  ylab("Rating Value")+
  ggtitle("Bar Plot of Passing")+
  theme(plot.title = element_text(hjust = 0.5))+
  coord_flip()
ggsave("./results/RV_bar.png")
```

```{r eval = FALSE,message=FALSE}
# Split the dataset into training and testing sets
data_split <- initial_split(data_eda, prop = 0.75, strata = RatingValue)
training_data <- training(data_split)
testing_data <- testing(data_split)
test_X <- testing_data %>%
    select(-Pass)
true_vals <- testing_data$Pass

# Fitting the models
mod <- glm(Pass~LocalAuthorityCode+BusinessType+Year+Month+Day, 
           data=training_data, family="binomial")

# Model evaluation
mod_sum <- summary(mod)
pred <- predict(mod, newdata=test_X, type = "response")
cut_off <- optimalCutoff(true_vals, pred)
final_predict <- ifelse(pred > cut_off, 1, 0)
final_predict <- as.factor(final_predict)
true_vals <- as.factor(true_vals)
conf <- confusionMatrix(true_vals, final_predict)
conf_mat <- as.table(conf)
acc <- as.matrix(as.matrix(conf,what="overall")[c(1,2,3,4,5),])
write.csv(acc,file="./results/accuracy.csv")
write.csv(conf_mat, file="./results/conf_mat.csv")
```

